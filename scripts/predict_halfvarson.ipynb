{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper_functions as hf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "importlib.reload(hf)\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26726\n",
      "26726\n",
      "(26726, 100)\n",
      "(25159, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_dir = \"C:/Users/ctata/Documents/Lab/quality_vectors_git/data/\"\n",
    "fig_dir = \"C:/Users/ctata/Documents/Lab/quality_vectors_git/figures/\"\n",
    "\n",
    "qual_vecs, embed_ids, embed_seqs = hf.getQualVecs(data_dir)\n",
    "\n",
    "\n",
    "\n",
    "otu = pd.read_csv(data_dir + \"halfvarson/seqtab.txt\", sep = \"\\t\")\n",
    "otu.shape\n",
    "\n",
    "mapping = pd.read_csv(data_dir + \"halfvarson/mapping.txt\", sep = \"\\t\")\n",
    "mapping = mapping.set_index(\"sample_name\")\n",
    "\n",
    "\n",
    "best_hits = pd.read_csv(data_dir + \"halfvarson/embed/best_hits.tsv\", header = None, sep = \"\\t\")\n",
    "best_hits.columns = [\"query_id\", \"hit_id\", \"query_seq\", \"hit_seq\", \"evalue\", \"bitscore\"]\n",
    "best_hits = best_hits.set_index('query_id')\n",
    "keep = [i < 1E-29 for i in best_hits['evalue'] ]\n",
    "best_hits = best_hits.loc[keep, :]\n",
    "print(best_hits.shape)\n",
    "best_hits\n",
    "\n",
    "\n",
    "#Get only those ASVs that have a match in the embedding set\n",
    "\n",
    "best_hits = best_hits.loc[[i in otu.columns.values for i in best_hits['query_seq']], :]\n",
    "otu_use = otu.loc[:, best_hits['query_seq'].values]\n",
    "\n",
    "#Assign id of best match and reorder columns\n",
    "otu_use.columns = best_hits.loc[:, 'hit_id']\n",
    "\n",
    "#Put transformation matrix in order to be dotted with the ASV table\n",
    "qual_vecs = qual_vecs.loc[otu_use.columns.values, :]\n",
    "\n",
    "\n",
    "#Keep only diagnoses we're interested in right now\n",
    "mapping['sample_name'] = mapping.index.values\n",
    "keep = [i in [\"CD\", \"UC\", \"HC\"] for i in mapping[\"diagnosis_full\"].values]\n",
    "mapping = mapping.loc[keep, :]\n",
    "mapping = mapping.loc[[i in otu_use.index.values for i in mapping.index.values], :]\n",
    "otu_use = otu_use.loc[mapping.index, :]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2127659574468085"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure patient numbers are not split btw train and test\n",
    "mapping[\"sample_id\"] = mapping.index.values\n",
    "np.random.seed(20)\n",
    "train_patient_nums = np.random.choice(np.unique(mapping.patientnumber), 170)\n",
    "test_patient_nums = np.unique(mapping.patientnumber[[(not i in train_patient_nums) for i in  mapping.patientnumber]])\n",
    "\n",
    "\n",
    "mapping = mapping.loc[[i in otu_use.index.values for i in mapping.index.values], :]\n",
    "map_train = mapping.loc[[i in train_patient_nums for i in mapping.patientnumber], :]\n",
    "map_test = mapping.loc[[i in test_patient_nums for i in mapping.patientnumber], :]\n",
    "otu_train = otu_use.loc[map_train.index.values, :]\n",
    "otu_test = otu_use.loc[map_test.index.values, :]\n",
    "otu_test.shape[0] / (otu_train.shape[0] + otu_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get CD/UC data\n",
    "def getDiagnosisInfo(otu_train, otu_test, map_train, map_test, pos_class, neg_class):\n",
    "    map_train = map_train.loc[[i in neg_class or i in pos_class for i in map_train.diagnosis_full], :]\n",
    "    map_test = map_test.loc[[i in neg_class or i in pos_class for i in map_test.diagnosis_full], :]\n",
    "    otu_train = otu_train.loc[map_train.index.values, :]\n",
    "    otu_test = otu_test.loc[map_test.index.values, :]\n",
    "    y_train = [i in pos_class for i in map_train.diagnosis_full.values]\n",
    "    y_test = [i in pos_class for i in map_test.diagnosis_full.values]\n",
    "    return(otu_train, otu_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_train_cd_uc, otu_test_cd_uc, y_train_cd_uc, y_test_cd_uc = getDiagnosisInfo(otu_train, otu_test, \n",
    "                                                                                map_train, map_test, \n",
    "                                                                                pos_class = \"UC\", neg_class = \"CD\")\n",
    "\n",
    "otu_train_cd_hc, otu_test_cd_hc, y_train_cd_hc, y_test_cd_hc = getDiagnosisInfo(otu_train, otu_test, \n",
    "                                                                                map_train, map_test, \n",
    "                                                                                pos_class = \"CD\", neg_class = \"HC\")\n",
    "\n",
    "otu_train_hc_uc, otu_test_hc_uc, y_train_hc_uc, y_test_hc_uc = getDiagnosisInfo(otu_train, otu_test, \n",
    "                                                                                map_train, map_test, \n",
    "                                                                                pos_class = \"UC\", neg_class = \"HC\")\n",
    "\n",
    "otu_train_hc_ibd, otu_test_hc_ibd, y_train_hc_ibd, y_test_hc_ibd = getDiagnosisInfo(otu_train, otu_test, \n",
    "                                                                                map_train, map_test, \n",
    "                                                                                pos_class = [\"CD\" , \"UC\"], neg_class = \"HC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainHyperParameters(X_train, y_train):\n",
    "\n",
    "    aucs = []\n",
    "    precisions = []\n",
    "    f1s = []\n",
    "    \n",
    "    depths = [2, 3, 5, 7]\n",
    "    n_estimators = [50, 70, 90, 110, 130]\n",
    "    weights = [1, 3, 5, 10, 15]\n",
    "    \n",
    "    #depths = [2, 3]\n",
    "    #n_estimators = [50, 70]\n",
    "    #weights = [1, 3]\n",
    "    \n",
    "    df = np.zeros((len(depths) * len(n_estimators) * len(weights), 6))\n",
    "    i = 0\n",
    "    for max_depth in depths:\n",
    "        for n_est in n_estimators:\n",
    "            for weight in weights:\n",
    "                #print(max_depth, n_est, weight, end = \"\\t\")\n",
    "                auc_crossVal, auc_prec_crossVal, f1_crossVal, _ = hf.crossValPrediction(X_train, y_train,\n",
    "                                                                                        max_depth = max_depth,\n",
    "                                                                                        n_estimators = n_est,\n",
    "                                                                                        weight = weight ,\n",
    "                                                                                        folds = 3)\n",
    "                df[i, :] = [np.mean(auc_crossVal), np.mean(auc_prec_crossVal), np.mean(f1_crossVal), \n",
    "                                   max_depth, n_est, weight]\n",
    "                i += 1\n",
    "   \n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getParamDfs(X_train, y_train):\n",
    "    \n",
    "    asin_params = trainHyperParameters(hf.asinh(X_train), y_train)\n",
    "\n",
    "    embedded = pd.DataFrame(np.dot(hf.asinh(X_train), qual_vecs))\n",
    "    embedded.columns = qual_vecs.columns.values\n",
    "    embed_params = trainHyperParameters(embedded, y_train)\n",
    "\n",
    "    pca = PCA(n_components= np.min([qual_vecs.shape[1], X_train.shape[0]]))\n",
    "    pca.fit(hf.asinh(X_train))\n",
    "    otu_pca = pd.DataFrame(pca.transform(hf.asinh(X_train)))\n",
    "    pca_params = trainHyperParameters(otu_pca, y_train)\n",
    "    \n",
    "    return(asin_params, embed_params, pca_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(params):\n",
    "    #f1 metric\n",
    "    tmp = params[np.argmax(params[:, 2]), :]\n",
    "    print(tmp)\n",
    "    return([int(i) for i in tmp[3:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(hf)\n",
    "\n",
    "def drawFigures(X_train, X_test, y_train, y_test, asin_params, embed_params, pca_params):\n",
    "    plot = False\n",
    "    f = plt.figure(figsize=(15,5))\n",
    "    _, roc_auc_asin, _, _, _, pr_auc_asin, _, _ = hf.predictIBD(X_train = hf.asinh(X_train),\n",
    "                                                                                X_test = hf.asinh(X_test),\n",
    "                                                                                y_train = y_train,\n",
    "                                                                                y_test = y_test,\n",
    "                                                                                max_depth = asin_params[0],\n",
    "                                                                                n_estimators = asin_params[1],\n",
    "                                                                                weight = asin_params[2],\n",
    "                                                                                plot = plot, plot_pr = plot)\n",
    "    print(\"Asinh\")\n",
    "    #print(otu_use.shape)\n",
    "    #print(np.mean(auc_crossVal))\n",
    "    #print(np.mean(auc_prec_crossVal))\n",
    "    f.savefig(fig_dir + \"curves_halfvarson_asin_tmp.pdf\")\n",
    "\n",
    "\n",
    "    embedded = pd.DataFrame(np.dot(hf.asinh(X_train), qual_vecs))\n",
    "    embedded.columns = qual_vecs.columns.values\n",
    "    \n",
    "    embedded_test = pd.DataFrame(np.dot(hf.asinh(X_test), qual_vecs))\n",
    "    embedded_test.columns = qual_vecs.columns.values\n",
    "\n",
    "    f = plt.figure(figsize=(15,5))\n",
    "    _, roc_auc_embed, _, _, _, pr_auc_embed, _, _ = hf.predictIBD(X_train = embedded,\n",
    "                                                                     X_test = embedded_test,\n",
    "                                                                     y_train = y_train,\n",
    "                                                                     y_test = y_test,\n",
    "                                                                     max_depth = embed_params[0],\n",
    "                                                                     n_estimators = embed_params[1],\n",
    "                                                                     weight = embed_params[2],\n",
    "                                                                     plot = plot, plot_pr = plot)\n",
    "    print(\"Embed\")\n",
    "    #print(embedded.shape)\n",
    "    #print(np.mean(auc_crossVal))\n",
    "    #print(np.mean(auc_prec_crossVal))\n",
    "    f.savefig(fig_dir + \"curves_halfvarson_embed_tmp.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "    f = plt.figure(figsize=(15,5))\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components= np.min([qual_vecs.shape[1], X_train.shape[0]]))\n",
    "    pca.fit(hf.asinh(X_train))\n",
    "    otu_pca = pd.DataFrame(pca.transform(hf.asinh(X_train)))\n",
    "    otu_pca_test = pd.DataFrame(pca.transform(hf.asinh(X_test)))\n",
    "    _, roc_auc_pca, _, _, _, pr_auc_pca, _, _ = hf.predictIBD(X_train = otu_pca,\n",
    "                                                               X_test = otu_pca_test, \n",
    "                                                               y_train = y_train,\n",
    "                                                               y_test = y_test,\n",
    "                                                               max_depth = pca_params[0],\n",
    "                                                               n_estimators = pca_params[1],\n",
    "                                                               weight = pca_params[2],\n",
    "                                                                plot = plot, plot_pr = plot)\n",
    "    print(\"PCA\")\n",
    "    #print(otu_pca.shape)\n",
    "    #print(np.mean(auc_crossVal))\n",
    "    #print(np.mean(auc_prec_crossVal))\n",
    "    #f.savefig(fig_dir + \"curves_halfvarson_pca_tmp.pdf\")\n",
    "    return(roc_auc_asin, pr_auc_asin, roc_auc_embed, pr_auc_embed, roc_auc_pca, pr_auc_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As training sizes decrease, how does each method perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250]\n",
    "n = len(train_sizes)\n",
    "df = pd.DataFrame({'train_size' : np.zeros(n), 'roc_asin': np.zeros(n), 'pr_asin':np.zeros(n),\n",
    "                                               'roc_embed': np.zeros(n), 'pr_embed':np.zeros(n),\n",
    "                                                'roc_pca': np.zeros(n), 'pr_pca':np.zeros(n)})\n",
    "i = 0\n",
    "\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    np.random.seed(20)\n",
    "    train_patient_nums = np.random.choice(np.unique(mapping.patientnumber), train_sizes[i])\n",
    "    test_patient_nums = np.unique(mapping.patientnumber[[(not i in train_patient_nums) for i in  mapping.patientnumber]])\n",
    "\n",
    "    mapping = mapping.loc[[i in otu_use.index.values for i in mapping.index.values], :]\n",
    "    map_train = mapping.loc[[i in train_patient_nums for i in mapping.patientnumber], :]\n",
    "    map_test = mapping.loc[[i in test_patient_nums for i in mapping.patientnumber], :]\n",
    "    otu_train = otu_use.loc[map_train.index.values, :]\n",
    "    otu_test = otu_use.loc[map_test.index.values, :]\n",
    "    otu_test.shape[0] / (otu_train.shape[0] + otu_test.shape[0])\n",
    "\n",
    "    df.train_size[i] = otu_train.shape[0]\n",
    "    \n",
    "    otu_train_hc_ibd, otu_test_hc_ibd, y_train_hc_ibd, y_test_hc_ibd = getDiagnosisInfo(otu_train, otu_test, \n",
    "                                                                                    map_train, map_test, \n",
    "                                                                                    pos_class = [\"CD\" , \"UC\"], neg_class = \"HC\")\n",
    "\n",
    "    asin_params_hc_ibd , embed_params_hc_ibd, pca_params_hc_ibd = getParamDfs(otu_train_hc_ibd, y_train_hc_ibd)\n",
    "    asin_params_hc_ibd_best = getBestParams(asin_params_hc_ibd)\n",
    "    embed_params_hc_ibd_best = getBestParams(embed_params_hc_ibd)\n",
    "    pca_params_hc_ibd_best = getBestParams(pca_params_hc_ibd)\n",
    "\n",
    "\n",
    "    roc_auc_asin, pr_auc_asin, roc_auc_embed, pr_auc_embed, roc_auc_pca, pr_auc_pca = drawFigures(otu_train_hc_ibd, otu_test_hc_ibd, y_train_hc_ibd, y_test_hc_ibd,\n",
    "                                                                                    asin_params_hc_ibd_best, embed_params_hc_ibd_best, pca_params_hc_ibd_best)\n",
    "    \n",
    "    df.roc_asin[i] = roc_auc_asin\n",
    "    df.pr_asin[i] = pr_auc_asin\n",
    "    df.roc_embed[i] = roc_auc_embed\n",
    "    df.pr_embed[i] = pr_auc_embed\n",
    "    df.roc_pca[i] = roc_auc_pca\n",
    "    df.pr_pca[i] = pr_auc_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotLineGraph(df):\n",
    "    f = plt.figure(figsize=(15,5))\n",
    "    flatui = [\"#9b59b6\", \"#3498db\", \"#e74c3c\", \"#2ecc71\"]\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(df.train_size, df.roc_asin, color = flatui[0])\n",
    "    plt.plot(df.train_size, df.roc_embed, color = flatui[1])\n",
    "    plt.plot(df.train_size, df.roc_pca, color = flatui[2])\n",
    "    plt.legend(labels = ['Asin', 'Embed', 'PCA'], loc = 'lower right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df.train_size, df.pr_asin, color = flatui[0])\n",
    "    plt.plot(df.train_size, df.pr_embed, color = flatui[1])\n",
    "    plt.plot(df.train_size, df.pr_pca, color = flatui[2])\n",
    "    \n",
    "    plt.legend(labels = ['Asin', 'Embed', 'PCA'], loc = 'lower right')\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plotLineGraph(df)\n",
    "f.savefig('../figures/halfvarson_performance_trainsize.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
